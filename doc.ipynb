{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "Process Processes are basically the programs that are dispatched from the ready state and are scheduled in the CPU for execution\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "text = '''Process: Processes are basically the programs that are dispatched from the ready state and are scheduled in the CPU for execution. PCB(Process Control Block) holds the concept of process. A process can create other processes which are known as Child Processes. The process takes more time to terminate and it is isolated means it does not share the memory with any other process.'''\n",
    "print(len(text))\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, 5)\n",
    "sentence_text = \" \".join(summary[0].words)\n",
    "print(sentence_text)\n",
    "# print(len(summary[0]))\n",
    "print(len(sentence_text))\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23419\n"
     ]
    }
   ],
   "source": [
    "text = '''hey everyone welcome back to my channel the new video I'm in my new apartment very excited for 2024 and I got a lot of requests uh you know when I made the spring boot tutorial to make videos on Kafka and more advanced uh content around spring boot Kafka and U you know all of these other other tools so we're going to do that and I'm going to focus uh on that for this year as well uh bring you some nice uh content you can apply more hands up on contribute to open source projects so you know my first open source contribution was in a Java project so I'm very excited for this video we're going to learn about Kafka introductory video and we'll follow up this video with other other videos as well so in this video obviously it it would it wouldn't be a nice video without a more Hands-On approach so obviously we'll be doing a Hands-On tutorial as well and using cloud services as well so you can actually see how people are using it in the real world Kafka and we're going to be using Ivan so if you want to check out the links in the description below you know when we did the spring boot tutorial people loved it uh when I used it and got a lot of nice feedback so why I'm recommending that is because uh you get uh some free credits as well if you check out the know sign up using the link in the description below and the best part is you don't have to add a credit card you can just sign up and get started with it and have some free credits to run um you know your on your iin platform so do check out the links in the description below and uh let's get started so talk about uh what this Apachi Kafka right so let's take a scenario over here imagine that uh you're going to your hometown or somewhere right you're going to another state and you're at a very busy train station and trains in this example we will take the trains let's say we call these uh we can relate the trains to messages right so the trains are constantly like arriving and parting from the platforms okay and these trains are carrying passengers now we can relate passengers to what data and they are carrying the passengers to various destinations okay that's what happens in the real world we all know that we have all been I assume to the train station so this is much like Apachi kfka a train station is like Apachi kfka it's powerful and uh you know what is aachi Kafka it's an open source stream processing software platform that's basically what Apachi Kafka is it's a train station like a train station right um not quite not quite literally but I'll explain to you in a bit more but uh when we talk about Kafka it is designed to handle realtime data feeds so it's like a messaging system that effectively produces um the the what do you call it the well not produces processes and moves the data from one point to another okay just like the train is moving the passengers okay and it is unique because it's capable of handling a very vast amount of data making it like a go-to choice for many companies that are dealing with large scale data operations okay Kunal this is cool Apachi Kafka let's say it's a it's a tool or whatever you want to call it right it's an open- Source um stream processing software that basically Al handles all the uh data feeds that we have from one point transfers from one point to another Point not a problem so let's say you have a live TV broadcast you're video conferencing you're playing a game online multiplayer games right so we understand this very simple train example all all cool okay question is why do we use Kafka that's the question number two so the the reason number one is it provides a very high throughput so Kafka can can handle a large amount of a large volume of messages like a highway is you know for example a highway is designed to accommodate a lot of traffic without any concession so it provides High throughput when we talk about the next point which is scalability so it can easily grow with your needs I gave you the train example so think of it as a modular train system so where you can add in more trains without overhauling the entire infrastructure reason number three why we use aachi kfka is fault tolerance so Kafka is um like you know a very well-designed Road Network that provides multiple paths so if one of the path is blocked so the train traffic or whatever you want to call it will reroute automatically ensuring that the data flow is not interrupted all right cool now let's talk a bit more about the components of Kafka some terminologies I'll obviously try to relate this in a real world example as well so let's take an example of a post office okay so in the post office obviously the first thing is the people are sending the letters okay me or you anyone who are just going to the post off it or the post box sending the letters in this terminology in terms of Kafka these are known as producers so a Kafka producer is like people who are sending the letters to a post office now the next terminology very important which is a Kafka cluster so Kafka cluster is the post of it itself which is managing all the flow of the letters okay Point number three terminology number three in Kafka is a consumer so consumer is uh like the recipient of the letters who will get the letter okay those are the consumers in Kafka and topics that is also Kafka terminology are the different categories for of the mail that you're sending for example document bills International main so on and so forth and in this system the letters which is what we representing the data with are continuously sent and received sorted and these are directed to the right people um and these people we can ter as applications okay effectively and reliably so these are some of the components of Kafka we'll obviously take a look at it as well uh in a real world example so uh in a let's say if we talk about an e-commerce platform right so when you place an order on a ecommer on an e-commerce website so many things happen in the background right so what happens you order uh you place your service place your order this is you're ordering the service then there's a Kafka topic which is basically a dedicated channel for order processing then the inventory service which is if it checks if the item is in the stock or not this is for the consumer so order service is what this is when you place your order which is the Kafka producer Kafka topic is the dedicated channel for the processing of death order the inventory service the e-commerce website will check whether the item is is on stock or not this is the consumer the shipping service which arranges for the delivery this is also the Kafka consumer notification service which sends you the other confirmation email and everything also consumer so each of these you know Services interact through Kafka and these ensure real time processing and reliability and efficiency and uh I have been talking for a bit now I think uh it will make uh click to you much more uh nicely when we do a Hands-On demo okay so let's try to see apachi kka using Ivan very simple to use free for you to get started no credit card requ you will get extra credits as well when you check out the links in the description below and when we do more real world projects more complex projects in when we do let's say an Apachi Kafka course or a spring boot course Ian will play a very crucial role because you know sort of like built for that for real world applications so let's take a look at a demo all right so what we're going to do is we're going to create a project and uh since we're talking about data streams we need let's say lots of data we need lots of data that we need to send to Kafka and then Kafka will process it where we get this lots of data not just for the sake of this tutorial but there may be any other case and any other example in which you might want a lot of data okay just for testing purposes or whatever so let's make a mini project that is going to help you solve this problem there's a nice library in Python called Faker that we can use to you know generate fake data let's say you already have a schema you need to generate a lot of fake data so we're going to use that and uh we're going to use cafka you know to process um process that data as well and uh that's what we're going to do so let's get started first things first we need to set up our Kafka uh cluster online uh that you can do on a pretty easily so check out the links in the description below and you'll get some free credits as well that you can play around with it and the best part is you don't have to add a credit card when you're getting started so you can just get started um like this okay so I'm here in my uh even console as you can see on the on the screen I'm going to click on on create a new service and when I click on create a new service here you can see there are a bunch of services so I'm going to select Apachi Kafka now on such s like Apachi Kafka you know we can also select our version you can select the cloud providers or whatever and uh I'm in Europe I can select um you know uh Germany or whatever it is giving me that's fine England is fine I live in I live in London and uh you can select the service plan so startup business and uh you know premium whatever but it's uh it's a free trial um because you get lots of credits uh as well and um you can give this uh service a name also so I will say cka demo should be fine and let me see if there's anything else needed nope I can select the versions but I'll just do the one that is default for now create service and start trial that's it that's how easy it was to set up kafa um on the on i1 now here you can see that uh the current uh deployment status you can see it's uh being building so it would show running in a while and you can connect as well uh this is something we'll be needing uh next and obviously we'll be we'll be using python uh we'll be making use of all of these uh service credentials as well and um here you can see there's the service URI host Port access key access certificate CA certificate as well so here basically we will save the access key which is this one if you just click on show I can just copy it right right um and then the access certificate as well we're going to store that in a file as well and the ca certificate as well we will store that in a file as well so let me just show store this I'm going to download this I'm going to download this and I'm going to download this so This access key you have to save it as service.>, <Sentence: PM so save save that in your in your file Now by default you know when we talk about c c producers they can push data only on some of the pre-created topics and in order to allow topics to be created uh on the Fly while you're pushing the first let's say some records or whatever you have to enable um Kafka um autocreate topics so if I go in my console if I just uh let's say go to go to next create a topic I can do this later let let's say I just skip the step for now okay and Integrations and connections I'll just do finish setup that's fine uh overview I get all my Integrations uh sorry all my service credentials and everything uh here if I go in my overview and in the overview I check out down in advanced there should be here somewhere configurations are [Music] here here we go advanced configurations and here we're going to click on the configure option okay so add configuration there we go now here we can actually search for Kafka or autocreate scafa autocreate topics enable this is the one I have to enable that how simple was that so that's why we're doing it you know um because by default it's not on so when we have to allow all the you know the topics uh to be created on the fly when you're pushing the records that's why this uh field has to be enabled and I think we also have to enable h the Kafka rest API which is known as I'm going to save this the car uh car Bas and that also you can do in the if I go in the overview Tab and car place done enable rest confirmation done okay so this is basically you know uh going to allow us to check that our producers uh check our producer and uh it's going to do that by reviewing that the the records that we push to the Aven console that you can find in the topics tab later on okay sounds good um cool so we're going we're going to do that not a problem and uh yeah let's move forward okay so here in my uh vs code project I'm going to set up my python client so you can use the Kafka python client to build your producer and all you need to do is you need to do pip install Kafka python oh my spelling mistake not a problem while that is happening I'm going to create a main py file and this is very simple what I'm going to do in the main.py file is okay so in the main.py file I'm just going to copy this past and uh copy this copy paste this code I'm not going to write it the entire thing because uh you know to save time be more concise in the tutorial but I'm going to explain obviously you know what this does um so we have just imported some uh some dependencies and set some correct uh parameters like we have the bootstrap server we have the SSL CA file the insert file the key file which all refer to the uh connection URI and the three certificate files that were that were mentioned um you know over here these ones right so that's basically what it is you have to save these files as this name that we just downloaded and I mentioned this already right and you can also check uh all the other parameters and everything available in the um I documentation and all sorts of things okay and uh one thing I want to mention is that when we push uh you know push this properly to Kafka we also need to transform them into string and we have to encode those in our sky that is what this uh you know line is uh this Lambda function is doing so we are ready to push our first message to Kafka so let's do that okay so I'm just going to call this um you know um going to call the producer.>, <Sentence: send uh method or function whatever you want to call it function and uh I'm going to do the I'm going to also call the flush function so this basically this command the flush is uh blocking the code from executing until all the async messages are sent so if I just run this now okay so here I have my terminal and we're doing a pizza delivery data so fake data for pizza delivery in my current folder which is this one I have um it's fine um I have all my files so I have these three files that I just download loed and I have this URI that I got from uh my overview tab in the connection service URI not a problem and I'm going to run this uh file let's see what we get okay no errors looks good so what happened is that uh if we go into our URL if I go into my topics here we go I see a topic has been created a test topic has been created okay default configuration all the things you can see over here cool so we did using Python and uh it seems to be working so far so we're doing step by step let's follow it step by step all right one more thing we can do is we can uh go to the this topic and if I go to messages and if I select the format as Json fetch messages hello world yay so cool so we have successfully integrated this all right very exciting let's move forward so far so good okay now let's get back to business here uh we're creating fake data for like um you know a pizza delivery chain so we want to push our orders let's say in a real world I will push all my orders let's say I'm getting so many orders uh dominoes or Pizza Hut or whatever Papa Jones uh we're going to push it to Apachi Kafka okay so as a pizza owner you will get all the calls and you will note down the client's name and the address and the phone number and all sorts of things so we're going to mimic this information we're going to install um what are we going to install we're going to install Faker we're going to install Faker so this will allow me to get fake data all right that is done cool if I create a new file or if I can just I can just write it over here uh I can say PR Faker import or I can just create a new file for you just to show you fake.>, <Sentence: py okay random fake data I got Martha Keller address random fake now I'm getting another fake another fake another fake another fake fake data okay sounds good cool so now our basic fake data is ready we have the structure of the data database as well we getting the name and address and the phone number and um cool nice and here we have let's say we have name address phone number but you can have other things as well and um even though we have uh the name and address and phone number it doesn't really tell you anything about about the pizza business okay so for example we need pizzas as well like pizzas and stuff so uh we can create a a pizza generator and we can create like a custom data provider and uh we have few options for pizzas let's say Margarita pepperoni um Kar pan pizza if from Domino's India that I really miss um so on and so forth right so what I'm going to do here is uh going to create a file right I'm going to say new file let's say pizza producer.>, <Sentence: add provider Pizza provider I can give it a range for I in range 0 to 10 print fake dot Pizza uncore name there you go all right so you can add um you know all sorts of things and um yeah do getting like a bunch of bunch of pzas over here now we have our building blocks we can create an order so for each call we're going to note down everyone every time a person calls us we'll note down their name address phone number and they can order one to 10 pizzas and for every Pizza they can also order additional top things and uh we're going to create fake orders and uh a function that will randomly generate order ID and um yeah let's see how we can do that so I'm not going to write the entire code line by line but I'm just going to show you and explain it to you okay the basic stuff is done but uh what I'm going to do now is we're going to elevate it a bit further so that you can explore yourself because let's admit it it's not a tutorial for python we're going to explain how you know Ivan works and Kafka works so you can figure out this um you know know the other code yourself assuming you already know python but the good thing is that you can also run this same lab on gitpod which I believe is uh pretty cool and uh all you have to do is you have to set the uh variables that I already showed you over here if you go in your overview tab here you can find all the all the variables so let's just um you know do that and uh here if I just go to my preview so we're going to follow what they say and it's going to be pretty simple but by the way you can also explore these uh code samples you know yourself here you can say a user login token and just follow these just going to follow these steps and just going to create my um you know um just link my Ian account okay by the way you can also run the same command on your local system so I showed you from scratch in the initial part of this demo uh connecting the Ian CA with u you know your local repository the python uh client which is a simple hello world application and then there's a you know deeper dive into it using Faker uh library that you can use so for example if I just run this command you can see that it's going to generate you know fake pizza and it's going to give these fake orders to Kafka if I just go to topics if I go to pizza orders uh and I go to messages I search in the form of Json and I fetch there you go all the fake data that we are sending so this is what is happening I am sending fake data to Kafka from my computer so Faker JS is Faker the python one is um sending this fake data fake orders as you can see it's keeping on sending keep on sending and Kafka stream here is uh happily taking these messages okay sounds good cool cool fetch messages you'll see there will be more now more than 23 64 messages okay so ideally the motive of this video was to explain to you about what Kafka is don't worry too much about these complex code samples because we haven't started the main course yet so if you want uh I can do a dedicated course where we can build such projects from scratch because I wanted to be wary of everyone's time and you know not bombard you with all the information so we just did a little small demo and then I just showed you some boiler plate code but uh I'm happy to do like a dedicated video and I think if by this video you were able to understand what is cavka how easy it is to work with Ivan then you know it was a huge success and if you want to Deep dive learn more there are some nice Ian guides you can check out they do some amazing workshops as well and you can can sign up to the with the link in the description below where you'll get a lot of uh you know you'll get some nice free credits to try out Ian as well and if you're interested uh for any specific topic let me know if you want me to create a video on I know I'm getting so much requests for spring boot uh and Kafka there was as well so I Tred to explain what Kafka is in simple terms in this video but yeah any dedicated topic you want me to explain or maybe you need a dedicated kka boot camp you know like a 30 video long Hands-On boot camp Camp just like the DSA one so let me know in the comment section below and we can make that happen all right so that was about it Apachi Kafka you know the it's like the central nervous system of data processing for many companies you can say that uh you know just such a great tool you know it's the the ability you know for example to high uh to handle the high volumes of data in real time with reliability and scalability makes it an indispensable in the world of big data and realtime uh analytics and uh whether it's for tracking your uh user activity on the website or processing Financial transactions or let's say you want to work with the iot devices data Kafka can play a crucial role in making sure that the right data gets to the right place at the right time thanks a lot for watching everyone if you have any questions let me know in the comment section below if you have any suggestions let me know in the comment section below if you want uh if you have let's say a request for another future videos or let's say a dedicated course let me know in the comment section video uh of this video because uh you know it's being used in so many open source projects as well and um you know it being open source as well so uh sooner or later you will encounter Kafka somewhere in your in your journey um or spring boot or other if you're working with Java you will encounter these tools so it's important that we you know talk about these being you know uh an advocate for like I did the Java boot camp and playlist so now people are like okay this is fine but how do you apply it in the real world when we look at the bigger projects please use so many other tools like Kafka like spring boot so yeah any questions any suggestions if you need to if you need a dedicated Hands-On course really long one just like I did the DSA one so let me know and uh yeah check out Ivan the link in the description below because if you sign up using that link you get some free credits so shout out to them for giving free credits to The Community and I'll see you in the next one have a great day bye'''\n",
    "print(len(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
