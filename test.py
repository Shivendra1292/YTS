# # import nltk
# # from nltk.corpus import stopwords
# # from nltk.tokenize import word_tokenize
# # from nltk.probability import FreqDist

# # def summarize_text(text, num_sentences=2):
# #     # Tokenize the text into words
# #     words = word_tokenize(text.lower())

# #     # Remove stopwords
# #     stop_words = set(stopwords.words("english"))
# #     words = [word for word in words if word not in stop_words]

# #     # Calculate frequency distribution of words
# #     freq_dist = FreqDist(words)

# #     # Sort the words by frequency
# #     sorted_words = sorted(freq_dist, key=freq_dist.get, reverse=True)

# #     # Get the top 'num_sentences' most frequent words
# #     top_words = sorted_words[:num_sentences]

# #     # Reconstruct the sentences containing the most frequent words
# #     summary = []
# #     for sentence in nltk.sent_tokenize(text):
# #         if any(word in word_tokenize(sentence.lower()) for word in top_words):
# #             summary.append(sentence)

# #     return ' '.join(summary)

# from gensim.summarization import summarize
# # Example usage
# text = '''hey everyone welcome back to my channel the new video I'm in my new apartment very excited for
#  2024 and I got a lot of requests uh you know when I made the spring boot tutorial to make videos on Kafka
#    and more advanced uh content around spring boot Kafka and U you know all of these other other tools so we're
#      going to do that and I'm going to focus uh on that for this year as well uh bring you some nice uh content
#        you can apply more hands up on contribute to open source projects so you know my first open source
#          contribution was in a Java project so I'm very excited for this video we're going to learn about
#            Kafka introductory video and we'll follow up this video with other other videos as well so in this 
#            video obviously it it would it wouldn't be a nice video without a more Hands-On approach so obviously
#              we'll be doing a Hands-On tutorial as well and using cloud services as well so you can actually see
#                how people are using it in the real world Kafka and we're going to be using Ivan so if you want to
#                  check out the links in the description below you know when we did the spring boot tutorial people loved it uh when I used it and got a lot of nice feedback so why I'm recommending that is because uh you get uh some free credits as well if you check out the know sign up using the link in the description below and the best part is you don't have to add a credit card you can just sign up and get started with it and have some free credits to run um you know your on your iin platform so do check out the links in the description below and uh let's get started so talk about uh what this Apachi Kafka right so let's take a scenario over here imagine that uh you're going to your hometown or somewhere right you're going to another state and you're at a very busy train station and trains in this example we will take the trains let's say we call these uh we can relate the trains to messages right so the trains are constantly like arriving and parting from the platforms okay and these trains are carrying passengers now we can relate passengers to what data and they are carrying the passengers to various destinations okay that's what happens in the real world we all know that we have all been I assume to the train station so this is much like Apachi kfka a train station is like Apachi kfka it's powerful and uh you know what is aachi Kafka it's an open source stream processing software platform that's basically what Apachi Kafka is it's a train station like a train station right um not quite not quite literally but I'll explain to you in a bit more but uh when we talk about Kafka it is designed to handle realtime data feeds so it's like a messaging system that effectively produces um the the what do you call it the well not produces processes and moves the data from one point to another okay just like the train is moving the passengers okay and it is unique because it's capable of handling a very vast amount of data making it like a go-to choice for many companies that are dealing with large scale data operations okay Kunal this is cool Apachi Kafka let's say it's a it's a tool or whatever you want to call it right it's an open- Source um stream processing software that basically Al handles all the uh data feeds that we have from one point transfers from one point to another Point not a problem so let's say you have a live TV broadcast you're video conferencing you're playing a game online multiplayer games right so we understand this very simple train example all all cool okay question is why do we use Kafka that's the question number two so the the reason number one is it provides a very high throughput so Kafka can can handle a large amount of a large volume of messages like a highway is you know for example a highway is designed to accommodate a lot of traffic without any concession so it provides High throughput when we talk about the next point which is scalability so it can easily grow with your needs I gave you the train example so think of it as a modular train system so where you can add in more trains without overhauling the entire infrastructure reason number three why we use aachi kfka is fault tolerance so Kafka is um like you know a very well-designed Road Network that provides multiple paths so if one of the path is blocked so the train traffic or whatever you want to call it will reroute automatically ensuring that the data flow is not interrupted all right cool now let's talk a bit more about the components of Kafka some terminologies I'll obviously try to relate this in a real world example as well so let's take an example of a post office okay so in the post office obviously the first thing is the people are sending the letters okay me or you anyone who are just going to the post off it or the post box sending the letters in this terminology in terms of Kafka these are known as producers so a Kafka producer is like people who are sending the letters to a post office now the next terminology very important which is a Kafka cluster so Kafka cluster is the post of it itself which is managing all the flow of the letters okay Point number three terminology number three in Kafka is a consumer so consumer is uh like the recipient of the letters who will get the letter okay those are the consumers in Kafka and topics that is also Kafka terminology are the different categories for of the mail that you're sending for example document bills International main so on and so forth and in this system the letters which is what we representing the data with are continuously sent and received sorted and these are directed to the right people um and these people we can ter as applications okay effectively and reliably so these are some of the components of Kafka we'll obviously take a look at it as well uh in a real world example so uh in a let's say if we talk about an e-commerce platform right so when you place an order on a ecommer on an e-commerce website so many things happen in the background right so what happens you order uh you place your service place your order this is you're ordering the service then there's a Kafka topic which is basically a dedicated channel for order processing then the inventory service which is if it checks if the item is in the stock or not this is for the consumer so order service is what this is when you place your order which is the Kafka producer Kafka topic is the dedicated channel for the processing of death order the inventory service the e-commerce website will check whether the item is is on stock or not this is the consumer the shipping service which arranges for the delivery this is also the Kafka consumer notification service which sends you the other confirmation email and everything also consumer so each of these you know Services interact through Kafka and these ensure real time processing and reliability and efficiency and uh I have been talking for a bit now I think uh it will make uh click to you much more uh nicely when we do a Hands-On demo okay so let's try to see apachi kka using Ivan very simple to use free for you to get started no credit card requ you will get extra credits as well when you check out the links in the description below and when we do more real world projects more complex projects in when we do let's say an Apachi Kafka course or a spring boot course Ian will play a very crucial role because you know sort of like built for that for real world applications so let's take a look at a demo all right so what we're going to do is we're going to create a project and uh since we're talking about data streams we need let's say lots of data we need lots of data that we need to send to Kafka and then Kafka will process it where we get this lots of data not just for the sake of this tutorial but there may be any other case and any other example in which you might want a lot of data okay just for testing purposes or whatever so let's make a mini project that is going to help you solve this problem there's a nice library in Python called Faker that we can use to you know generate fake data let's say you already have a schema you need to generate a lot of fake data so we're going to use that and uh we're going to use cafka you know to process um process that data as well and uh that's what we're going to do so let's get started first things first we need to set up our Kafka uh cluster online uh that you can do on a pretty easily so check out the links in the description below and you'll get some free credits as well that you can play around with it and the best part is you don't have to add a credit card when you're getting started so you can just get started um like this okay so I'm here in my uh even console as you can see on the on the screen I'm going to click on on create a new service and when I click on create a new service here you can see there are a bunch of services so I'm going to select Apachi Kafka now on such s like Apachi Kafka you know we can also select our version you can select the cloud providers or whatever and uh I'm in Europe I can select um you know uh Germany or whatever it is giving me that's fine England is fine I live in I live in London and uh you can select the service plan so startup business and uh you know premium whatever but it's uh it's a free trial um because you get lots of credits uh as well and um you can give this uh service a name also so I will say cka demo should be fine and let me see if there's anything else needed nope I can select the versions but I'll just do the one that is default for now create service and start trial that's it that's how easy it was to set up kafa um on the on i1 now here you can see that uh the current uh deployment status you can see it's uh being building so it would show running in a while and you can connect as well uh this is something we'll be needing uh next and obviously we'll be we'll be using python uh we'll be making use of all of these uh service credentials as well and um here you can see there's the service URI host Port access key access certificate CA certificate as well so here basically we will save the access key which is this one if you just click on show I can just copy it right right um and then the access certificate as well we're going to store that in a file as well and the ca certificate as well we will store that in a file as well so let me just show store this I'm going to download this I'm going to download this and I'm going to download this so This access key you have to save it as service.>, <Sentence: PM so save save that in your in your file Now by default you know when we talk about c c producers they can push data only on some of the pre-created topics and in order to allow topics to be created uh on the Fly while you're pushing the first let's say some records or whatever you have to enable um Kafka um autocreate topics so if I go in my console if I just uh let's say go to go to next create a topic I can do this later let let's say I just skip the step for now okay and Integrations and connections I'll just do finish setup that's fine uh overview I get all my Integrations uh sorry all my service credentials and everything uh here if I go in my overview and in the overview I check out down in advanced there should be here somewhere configurations are [Music] here here we go advanced configurations and here we're going to click on the configure option okay so add configuration there we go now here we can actually search for Kafka or autocreate scafa autocreate topics enable this is the one I have to enable that how simple was that so that's why we're doing it you know um because by default it's not on so when we have to allow all the you know the topics uh to be created on the fly when you're pushing the records that's why this uh field has to be enabled and I think we also have to enable h the Kafka rest API which is known as I'm going to save this the car uh car Bas and that also you can do in the if I go in the overview Tab and car place done enable rest confirmation done okay so this is basically you know uh going to allow us to check that our producers uh check our producer and uh it's going to do that by reviewing that the the records that we push to the Aven console that you can find in the topics tab later on okay sounds good um cool so we're going we're going to do that not a problem and uh yeah let's move forward okay so here in my uh vs code project I'm going to set up my python client so you can use the Kafka python client to build your producer and all you need to do is you need to do pip install Kafka python oh my spelling mistake not a problem while that is happening I'm going to create a main py file and this is very simple what I'm going to do in the main.py file is okay so in the main.py file I'm just going to copy this past and uh copy this copy paste this code I'm not going to write it the entire thing because uh you know to save time be more concise in the tutorial but I'm going to explain obviously you know what this does um so we have just imported some uh some dependencies and set some correct uh parameters like we have the bootstrap server we have the SSL CA file the insert file the key file which all refer to the uh connection URI and the three certificate files that were that were mentioned um you know over here these ones right so that's basically what it is you have to save these files as this name that we just downloaded and I mentioned this already right and you can also check uh all the other parameters and everything available in the um I documentation and all sorts of things okay and uh one thing I want to mention is that when we push uh you know push this properly to Kafka we also need to transform them into string and we have to encode those in our sky that is what this uh you know line is uh this Lambda function is doing so we are ready to push our first message to Kafka so let's do that okay so I'm just going to call this um you know um going to call the producer.>, <Sentence: send uh method or function whatever 
#                  you want to call it function and uh I'm going to do the I'm going to also call the flush function so this basically this command the flush is uh blocking the code from executing until all the async messages are sent so if I just run this now okay so here I have my terminal and we're doing a pizza delivery data so fake data for pizza delivery in my current folder which is this one I have um it's fine um I have all my files so I have these three files that I just download loed and I have this URI that I got from uh my overview tab in the connection service URI not a problem and I'm going to run this uh file let's see what we get okay no errors looks good so what happened is that uh if we go into our URL if I go into my topics here we go I see a topic has been created a test topic has been created okay default configuration all the things you can see over here cool so we did using Python and uh it seems to be working so far so we're doing step by step let's follow it step by step all right one more thing we can do is we can uh go to the this topic and if I go to messages and if I select the format as Json fetch messages hello world yay so cool so we have successfully integrated this all right very exciting let's move forward so far so good okay now let's get back to business here uh we're creating fake data for like um you know a pizza delivery chain so we want to push our orders let's say in a real world I will push all my orders let's say I'm getting so many orders uh dominoes or Pizza Hut or whatever Papa Jones uh we're going to push it to Apachi Kafka okay so as a pizza owner you will get all the calls and you will note down the client's name and the address and the phone number and all sorts of things so we're going to mimic this information we're going to install um what are we going to install we're going to install Faker we're going to install Faker so this will allow me to get fake data all right that is done cool if I create a new file or if I can just I can just write it over here uh I can say PR Faker import or I can just create a new file for you just to show you fake.>, <Sentence: py okay random fake data I got Martha Keller address random fake now I'm getting another fake another fake another fake another fake fake data okay sounds good cool so now our basic fake data is ready we have the structure of the data database as well we getting the name and address and the phone number and um cool nice and here we have let's say we have name address phone number but you can have other things as well and um even though we have uh the name and address and phone number it doesn't really tell you anything about about the pizza business okay so for example we need pizzas as well like pizzas and stuff so uh we can create a a pizza generator and we can create like a custom data provider and uh we have few options for pizzas let's say Margarita pepperoni um Kar pan pizza if from Domino's India that I really miss um so on and so forth right so what I'm going to do here is uh going to create a file right I'm going to say new file let's say pizza producer.>, <Sentence: add provider Pizza provider I can give it a range for I in range 0 to 10 print fake dot Pizza uncore name there you go all right so you can add um you know all sorts of things and um yeah do getting like a bunch of bunch of pzas over here now we have our building blocks we can create an order so for each call we're going to note down everyone every time a person calls us we'll note down their name address phone number and they can order one to 10 pizzas and for every Pizza they can also order additional top things and uh we're going to create fake orders and uh a function that will randomly generate order ID and um yeah let's see how we can do that so I'm not going to write the entire code line by line but I'm just going to show you and explain it to you okay the basic stuff is done but uh what I'm going to do now is we're going to elevate it a bit further so that you can explore yourself because let's admit it it's not a tutorial for python we're going to explain how you know Ivan works and Kafka works so you can figure out this um you know know the other code yourself assuming you already know python but the good thing is that you can also run this same lab on gitpod which I believe is uh pretty cool and uh all you have to do is you have to set the uh variables that I already showed you over here if you go in your overview tab here you can find all the all the variables so let's just um you know do that and uh here if I just go to my preview so we're going to follow what they say and it's going to be pretty simple but by the way you can also explore these uh code samples you know yourself here you can say a user login token and just follow these just going to follow these steps and just going to create my um you know um just link my Ian account okay by the way you can also run the same command on your local system so I showed you from scratch in the initial part of this demo uh connecting the Ian CA with u you know your local repository the python uh client which is a simple hello world application and then there's a you know deeper dive into it using Faker uh library that you can use so for example if I just run this command you can see that it's going to generate you know fake pizza and it's going to give these fake orders to Kafka if I just go to topics if I go to pizza orders uh and I go to messages I search in the form of Json and I fetch there you go all the fake data that we are sending so this is what is happening I am sending fake data to Kafka from my computer so Faker JS is Faker the python one is um sending this fake data fake orders as you can see it's keeping on sending keep on sending and Kafka stream here is uh happily taking these messages okay sounds good cool cool fetch messages you'll see there will be more now more than 23 64 messages okay so ideally the motive of this video was to explain to you about what Kafka is don't worry too much about these complex code samples because we haven't started the main course yet so if you want uh I can do a dedicated course where we can build such projects from scratch because I wanted to be wary of everyone's time and you know not bombard you with all the information so we just did a little small demo and then I just showed you some boiler plate code but uh I'm happy to do like a dedicated video and I think if by this video you were able to understand what is cavka how easy it is to work with Ivan then you know it was a huge success and if you want to Deep dive learn more there are some nice Ian guides you can check out they do some amazing workshops as well and you can can sign up to the with the link in the description below where you'll get a lot of uh you know you'll get some nice free credits to try out Ian as well and if you're interested uh for any specific topic let me know if you want me to create a video on I know I'm getting so much requests for spring boot uh and Kafka there was as well so I Tred to explain what Kafka is in simple terms in this video but yeah any dedicated topic you want me to explain or maybe you need a dedicated kka boot camp you know like a 30 video long Hands-On boot camp Camp just like the DSA one so let me know in the comment section below and we can make that happen all right so that was about it Apachi Kafka you know the it's like the central nervous system of data processing for many companies you can say that uh you know just such a great tool you know it's the the ability you know for example to high uh to handle the high volumes of data in real time with reliability and scalability makes it an indispensable in the world of big data and realtime uh analytics and uh whether it's for tracking your uh user activity on the website or processing Financial transactions or let's say you want to work with the iot devices data Kafka can play a crucial role in making sure that the right data gets to the right place at the right time thanks a lot for watching everyone if you have any questions let me know in the comment section below if you have any suggestions let me know in the comment section below if you want uh if you have let's say a request for another future videos or let's say a dedicated course let me know in the comment section video uh of this video because uh you know it's being used in so many open source projects as well and um you know it being open source as well so uh sooner or later you will encounter Kafka somewhere in your in your journey um or spring boot or other if you're working with Java you will encounter these tools so it's important that we you know talk about
#                    these being you know uh an advocate for like I did the Java boot camp and playlist so now people are like okay this is fine but how do you apply it in the real world when we look at the bigger projects please use so many other tools like Kafka like spring boot so yeah any questions any suggestions if you need to if you need a dedicated Hands-On course really long one just like I did the DSA one so let me know and uh yeah check out Ivan the link in the description below because if you sign up using that link you get some free credits so shout out to them for giving free credits to The Community and I'll see you in the next one have a great day bye'''

# text2 = '''A tuple is immutable which means once it is created then, you cannot change its values. 
# Tuples are defined by parentheses() and elements/items separated by commas(,) in it. Whereas, The Lists
#  are the same as tuples but they are mutable which means that you can modify/Change the values. The list 
#    is defined by square brackets[].'''
# print(len(text2))
# print(summarize(text2))
# print(len(summarize(text2)))


import spacy
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer

# Load the English model in spaCy
nlp = spacy.load("en_core_web_sm")

# Example text
text = """hey everyone welcome back to my channel the new video I'm in my new apartment very excited for 2024 and 
I got a lot of requests uh you know when I made the spring boot tutorial to make videos on Kafka and more 
advanced uh content around spring boot Kafka and U you know all of these other other tools so we're going to do 
that and I'm going to focus uh on that for this year as well uh bring you some nice uh content you can apply more 
hands up on contribute to open source projects so you know my first open source contribution was in a Java 
project so I'm very excited for this video we're going to learn about Kafka introductory video and we'll follow 
up this video with other other videos as well so in this video obviously it it would it wouldn't be a nice video 
without a more Hands-On approach so obviously we'll be doing a Hands-On tutorial as well and using cloud services 
as well so you can actually see how people are using it in the real world Kafka and we're going to be using Ivan 
so if you want to check out the links in the description below you know when we did the spring boot tutorial 
people loved it uh when I used it and got a lot of nice feedback so why I'm recommending that is because uh you 
get uh some free credits as well if you check out the know sign up using the link in the description below and 
the best part is you don't have to add a credit card you can just sign up and get started with it and have some 
free credits to run um you know your on your iin platform so do check out the links in the description below and 
uh let's get started so talk about uh what this Apachi Kafka right so let's take a scenario over here imagine 
that uh you're going to your hometown or somewhere right you're going to another state and you're at a very busy 
train station and trains in this example we will take the trains let's say we call these uh we can relate the 
trains to messages right so the trains are constantly like arriving and parting from the platforms okay and these 
trains are carrying passengers now we can relate passengers to what data and they are carrying the passengers to 
various destinations okay that's what happens in the real world we all know that we have all been I assume to the 
train station so this is much like Apachi kfka a train station is like Apachi kfka it's powerful and uh you know 
what is aachi Kafka it's an open source stream processing software platform that's basically what Apachi Kafka is 
it's a train station like a train station right um not quite not quite literally but I'll explain to you in a bit 
more but uh when we talk about Kafka it is designed to handle realtime data feeds so it's like a messaging system 
that effectively produces um the the what do you call it the well not produces processes and moves the data from 
one point to another okay just like the train is moving the passengers okay and it is unique because it's capable 
of handling a very vast amount of data making it like a go-to choice for many companies that are dealing with 
large scale data operations okay Kunal this is cool Apachi Kafka let's say it's a it's a tool or whatever you 
want to call it right it's an open- Source um stream processing software that basically Al handles all the uh 
data feeds that we have from one point transfers from one point to another Point not a problem so let's say you 
have a live TV broadcast you're video conferencing you're playing a game online multiplayer games right so we 
understand this very simple train example all all cool okay question is why do we use Kafka that's the question 
number two so the the reason number one is it provides a very high throughput so Kafka can can handle a large 
amount of a large volume of messages like a highway is you know for example a highway is designed to accommodate 
a lot of traffic without any concession so it provides High throughput when we talk about the next point which is 
scalability so it can easily grow with your needs I gave you the train example so think of it as a modular train 
system so where you can add in more trains without overhauling the entire infrastructure reason number three why 
we use aachi kfka is fault tolerance so Kafka is um like you know a very well-designed Road Network that provides 
multiple paths so if one of the path is blocked so the train traffic or whatever you want to call it will reroute 
automatically ensuring that the data flow is not interrupted all right cool now let's talk a bit more about the 
components of Kafka some terminologies I'll obviously try to relate this in a real world example as well so let's 
take an example of a post office okay so in the post office obviously the first thing is the people are sending 
the letters okay me or you anyone who are just going to the post off it or the post box sending the letters in this terminology in terms of Kafka these are known as producers so a Kafka producer is like people who are sending the letters to a post office now the next terminology very important which is a Kafka cluster so Kafka cluster is the post of it itself which is managing all the flow of the letters okay Point number three terminology number three in Kafka is a consumer so consumer is uh like the recipient of the letters who will get the letter okay those are the consumers in Kafka and topics that is also Kafka terminology are the different categories for of the mail that you're sending for example document bills International main so on and so forth and in this system the letters which is what we representing the data with are continuously sent and received sorted and these are directed to the right people um and these people we can ter as applications okay effectively and reliably so these are some of the components of Kafka we'll obviously take a look at it as well uh in a real world example so uh in a let's say if we talk about an e-commerce platform right so when you place an order on a ecommer on an e-commerce website so many things happen in the background right so what happens you order uh you place your service place your order this is you're ordering the service then there's a Kafka topic which is basically a dedicated channel for order processing then the inventory service which is if it checks if the item is in the stock or not this is for the consumer so order service is what this is when you place your order which is the Kafka producer Kafka topic is the dedicated channel for the processing of death order the inventory service the e-commerce website will check whether the item is is on stock or not this is the consumer the shipping service which arranges for the delivery this is also the Kafka consumer notification service which sends you the other confirmation email and everything also consumer so each of these you know Services interact through Kafka and these ensure real time processing and reliability and efficiency and uh I have been talking for a bit now I think uh it will make uh click to you much more uh nicely when we do a Hands-On demo okay so let's try to see apachi kka using Ivan very simple to use free for you to get started no credit card requ you will get extra credits as well when you check out the links in the description below and when we do more real world projects more complex projects in when we do let's say an Apachi Kafka course or a spring boot course Ian will play a very crucial role because you know sort of like built for that for real world applications so let's take a look at a demo all right so what we're going to do is we're going to create a project and uh since we're talking about data streams we need let's say lots of data we need lots of data that we need to send to Kafka and then Kafka will process it where we get this lots of data not just for the sake of this tutorial but there may be any other case and any other example in which you might want a lot of data okay just for testing purposes or whatever so let's make a mini project that is going to help you solve this problem there's a nice library in Python called Faker that we can use to you know generate fake data let's say you already have a schema you need to generate a lot of fake data so we're going to use that and uh we're going to use cafka you know to process um process that data as well and uh that's what we're going to do so let's get started first things first we need to set up our Kafka uh cluster online uh that you can do on a pretty easily so check out the links in the description below and you'll get some free credits as well that you can play around with it and the best part is you don't have to add a credit card when you're getting started so you can just get started um like this okay so I'm here in my uh even console as you can see on the on the screen I'm going to click on on create a new service and when I click on create a new service here you can see there are a bunch of services so I'm going to select Apachi Kafka now on such s like Apachi Kafka you know we can also select our version you can select the cloud providers or whatever and uh I'm in Europe I can select um you know uh Germany or whatever it is giving me that's fine England is fine I live in I live in London and uh you can select the service plan so startup business and uh you know premium whatever but it's uh it's a free trial um because you get lots of credits uh as well and um you can give this uh service a name also so I will say cka demo should be fine and let me see if there's anything else needed nope I can select the versions but I'll just do the one that is default for now create service and start trial that's it that's how easy it was to set up kafa um on the on i1 now here you can see that uh the current uh deployment status you can see it's uh being building so it would show running in a while and you can connect as well uh this is something we'll be needing uh next and obviously we'll be we'll be using python uh we'll be making use of all of these uh service credentials as well and um here you can see there's the service URI host Port access key access certificate CA certificate as well so here basically we will save the access key which is this one if you just click on show I can just copy it right right um and then the access certificate as well we're going to store that in a file as well and the ca certificate as well we will store that in a file as well so let me just show store this I'm going to download this I'm going to download this and I'm going to download this so This access key you have to save it as service. key file the service doert file is the access certificate and the ca certificate you have to save as ca. PM so save save that in your in your file Now by default you know when we talk about c c producers they can push data only on some of the pre-created topics and in order to allow topics to be created uh on the Fly while you're pushing the first let's say some records or whatever you have to enable um Kafka um autocreate topics so if I go in my console if I just uh let's say go to go to next create a topic I can do this later let let's say I just skip the step for now okay and Integrations and connections I'll just do finish setup that's fine uh overview I get all my Integrations uh sorry all my service credentials and everything uh here if I go in my overview and in the overview I check out down in advanced there should be here somewhere configurations are [Music] here here we go advanced configurations and here we're going to click on the configure option okay so add configuration there we go now here we can actually search for Kafka or autocreate scafa autocreate topics enable this is the one I have to enable that how simple was that so that's why we're doing it you know um because by default it's not on so when we have to allow all the you know the topics uh to be created on the fly when you're pushing the records that's why this uh field has to be enabled and I think we also have to enable h the Kafka rest API which is known as I'm going to save this the car uh car Bas and that also you can do in the if I go in the overview Tab and car place done enable rest confirmation done okay so this is basically you know uh going to allow us to check that our producers uh check our producer and uh it's going to do that by reviewing that the the records that we push to the Aven console that you can find in the topics tab later on okay sounds good um cool so we're going we're going to do that not a problem and uh yeah let's move forward okay so here in my uh vs code project I'm going to set up my python client so you can use the Kafka python client to build your producer and all you need to do is you need to do pip install Kafka python oh my spelling mistake not a problem while that is happening I'm going to create a main py file and this is very simple what I'm going to do in the main.py file is okay so in the main.py file I'm just going to copy this past and uh copy this copy paste this code I'm not going to write it the entire thing because uh you know to save time be more concise in the tutorial but I'm going to explain obviously you know what this does um so we have just imported some uh some dependencies and set some correct uh parameters like we have the bootstrap server we have the SSL CA file the insert file the key file which all refer to the uh connection URI and the three certificate files that were that were mentioned um you know over here these ones right so that's basically what it is you have to save these files as this name that we just downloaded and I mentioned this already right and you can also check uh all the other parameters and everything available in the um I documentation and all sorts of things okay and uh one thing I want to mention is that when we push uh you know push this properly to Kafka we also need to transform them into string and we have to encode those in our sky that is what this uh you know line is uh this Lambda function is doing so we are ready to push our first message to Kafka so let's do that okay so I'm just going to call this um you know um going to call the producer. send uh method or function whatever you want to call it function and uh I'm going to do the I'm going to also call the flush function so this basically this command the flush is uh blocking the code from executing until all the async messages are sent so if I just run this now okay so here I have my terminal and we're doing a pizza delivery data so fake data for pizza delivery in my current folder which is this one I have um it's fine um I have all my files so I have these three files that I just download loed and I have this URI that I got from uh my overview tab in the connection service URI not a problem and I'm going to run this uh file let's see what we get okay no errors looks good so what happened is that uh if we go into our URL if I go into my topics here we go I see a topic has been created a test topic has been created okay default configuration all the things you can see over here cool so we did using Python and uh it seems to be working so far so we're doing step by step let's follow it step by step all right one more thing we can do is we can uh go to the this topic and if I go to messages and if I select the format as Json fetch messages hello world yay so cool so we have successfully integrated this all right very exciting let's move forward so far so good okay now let's get back to business here uh we're creating fake data for like um you know a pizza delivery chain so we want to push our orders let's say in a real world I will push all my orders let's say I'm getting so many orders uh dominoes or Pizza Hut or whatever Papa Jones uh we're going to push it to Apachi Kafka okay so as a pizza owner you will get all the calls and you will note down the client's name and the address and the phone number and all sorts of things so we're going to mimic this information we're going to install um what are we going to install we're going to install Faker we're going to install Faker so this will allow me to get fake data all right that is done cool if I create a new file or if I can just I can just write it over here uh I can say PR Faker import or I can just create a new file for you just to show you fake. py okay so I can say from Faker import Faker and going to call this um class uh Constructor create an object and then I'm going to create a message let's say for the pizza delivery we have a name fake name similarly we have address fake address similarly we have phone PI phone number this is a very useful uh you know thing for you if you want to create fake data for testing purposes or whatever and you know you don't want to worry about um you don't want to worry about um you know where to get the data or whatever so if I just have a you know this simple file and I just run this so fake. py okay random fake data I got Martha Keller address random fake now I'm getting another fake another fake another fake another fake fake data okay sounds good cool so now our basic fake data is ready we have the structure of the data database as well we getting the name and address and the phone number and um cool nice and here we have let's say we have name address phone number but you can have other things as well and um even though we have uh the name and address and phone number it doesn't really tell you anything about about the pizza business okay so for example we need pizzas as well like pizzas and stuff so uh we can create a a pizza generator and we can create like a custom data provider and uh we have few options for pizzas let's say Margarita pepperoni um Kar pan pizza if from Domino's India that I really miss um so on and so forth right so what I'm going to do here is uh going to create a file right I'm going to say new file let's say pizza producer. py I'm going to copy this so you have pepperoni salami Margarita all sorts of pizzas that you have created your own custom type now in the main I can actually um just import the pza provider I can say from Pizza producer import Pizza provider okay and here I can say or actually I can do it here and I can remove this now I can just say fake. add fake. add provider Pizza provider I can give it a range for I in range 0 to 10 print fake dot Pizza uncore name there you go all right so you can add um you know all sorts of things and um yeah do getting like a bunch of bunch of pzas over here now we have our building blocks we can create an order so for each call we're going to note down everyone every time a person calls us we'll note down their name address phone number and they can order one to 10 pizzas and for every Pizza they can also order additional top things and uh we're going to create fake orders and uh a function that will randomly generate order ID and um yeah let's see how we can do that so I'm not going to write the entire code line by line but I'm just going to show you and explain it to you okay the basic stuff is done but uh what I'm going to do now is we're going to elevate it a bit further so that you can explore yourself because let's admit it it's not a tutorial for python we're going to explain how you know Ivan works and Kafka works so you can figure out this um you know know the other code yourself assuming you already know python but the good thing is that you can also run this same lab on gitpod which I believe is uh pretty cool and uh all you have to do is you have to set the uh variables that I already showed you over here if you go in your overview tab here you can find all the all the variables so let's just um you know do that and uh here if I just go to my preview so we're going to follow what they say and it's going to be pretty simple but by the way you can also explore these uh code samples you know yourself here you can say a user login token and just follow these just going to follow these steps and just going to create my um you know um just link my Ian account okay by the way you can also run the same command on your local system so I showed you from scratch in the initial part of this demo uh connecting the Ian CA with u you know your local repository the python uh client which is a simple hello world application and then there's a you know deeper dive into it using Faker uh library that you can use so for example if I just run this command you can see that it's going to generate you know fake pizza and it's going to give these fake orders to Kafka if I just go to topics if I go to pizza orders uh and I go to messages I search in the form of Json and I fetch there you go all the fake data that we are sending so this is what is happening I am sending fake data to Kafka from my computer so Faker JS is Faker the python one is um sending this fake data fake orders as you can see it's keeping on sending keep on sending and Kafka stream here is uh happily taking these messages okay sounds good cool cool fetch messages you'll see there will be more now more than 23 64 messages okay so ideally the motive of this video was to explain to you about what Kafka is don't worry too much about these complex code samples because we haven't started the main course yet so if you want uh I can do a dedicated course where we can build such projects from scratch because I wanted to be wary of everyone's time and you know not bombard you with all the information so we just did a little small demo and then I just showed you some boiler plate code but uh I'm happy to do like a dedicated video and I think if by this video you were able to understand what is cavka how easy it is to work with Ivan then you know it was a huge success and if you want to Deep dive learn more there are some nice Ian guides you can check out they do some amazing workshops as well and you can can sign up to the with the link in the description below where you'll get a lot of uh you know you'll get some nice free credits to try out Ian as well and if you're interested uh for any specific topic let me know if you want me to create a video on I know I'm getting so much requests for spring boot uh and Kafka there was as well so I Tred to explain what Kafka is in simple terms in this video but yeah any dedicated topic you want me to explain or maybe you need a dedicated kka boot camp you know like a 30 video long Hands-On boot camp Camp just like the DSA one so let me know in the comment section below and we can make that happen all right so that was about it Apachi Kafka you know the it's like the central nervous system of data processing for many companies you can say that uh you know just such a great tool you know it's the the ability you know for example to high uh to handle the high volumes of data in real time with reliability and scalability makes it an indispensable in the world of big data and realtime uh analytics and uh whether it's for tracking your uh user activity on the website or processing Financial transactions or let's say you want to work with the iot devices data Kafka can play a crucial role in making sure that the right data gets to the right place at the right time thanks a lot for watching everyone if you have any questions let me know in the comment section below if you have any suggestions let me know in the comment section below if you want uh if you have let's say a request for another future videos or let's say a dedicated course let me know in the comment section video uh of this video because uh you know it's being used in so many open source projects as well and um you know it being open source as well so uh sooner or later you will encounter Kafka somewhere in your in your journey um or spring boot or other if you're working with Java you will encounter these tools so it's important that we you know talk about these being you know uh an advocate for like I did the Java boot camp and playlist so now people are like okay this is fine but how do you apply it in the real world when we look at the bigger projects please use so many other tools like Kafka like spring boot so yeah any questions any suggestions if you need to if you need a dedicated Hands-On course really long one just like I did the DSA one so let me know and uh yeah check out Ivan the link in the description below because if you sign up using that link you get some free credits so shout out to them for giving free credits to The Community and I'll see you in the next one have a great day bye"""

text = '''hey everyone welcome back to my channel the new video I'm making this video because uh in the past uh I have created some webd tutorials and I recently launched my uh Genna uh and introduction to rag course which is going very well a few thousand signups already so make sure you you know check that out and the question. I'm getting quite a lot is Kunal when we create our you know websites and projects when you do research work and like you universities or or you know other areas and uh when you're training your machine learning models and all these things that I've been doing a common question in all of these domains that I get is where do you get the data from right so there are some publicly available data online some people you know script the websites and get data from that and some people use like uh temporary data using psyit learn or whatever but uh the main question that I have gotten is Kunal when you're trying to get some real world data that is publicly available even though it's publicly available it's not easy and I think data is a very important topic to speak about both in terms of like you know data security the ethical considerations of how to use data how to manage large scale data and then all the tools revolving around that so this video is going to be beneficial for you you know if you're looking to find uh data to train your machine learning models for your own research work for your projects and all sorts of things because I'm doing a machine learning course uh like a mini course and I'll be doing a main machine learning course uh later on as well this video is going to be highly relevant U so we're going to talk about how do we scrape data from the websites and publicly available information in an ethical way before we get started with that I want to share a bit around my experiences with um you know the problems that I have when trying to scrape data from the internet and let me know in the comment section below if you suffer from the same challenges so in my experience with data scraping I've encountered like several challenges that can make the collection process quite tricky and you know technical hurdles legal restrictions and also ethical considerations all play a role in shaping the landscape of data extraction depends you know where you're extracting the data from one of the most noticeable and notable challenges that I have faced is dealing with B detection mechanisms on the websites now if you don't know what that is you know these systems are set up to spot automated scraping activities and can be quite sophisticated so they analyze things like user agent strings and request rates to differentiate between a human user and Bots which can sometimes you know put a road block uh road block in my um in my scraping efforts right other than that uh you know another obstacle that I have come across is uh solving captas during the scraping process and these challenges are specifically designed uh you know to readed out Bots by presenting tasks that are easy for humans but difficult for machines you may have seen like captas right and uh you might be saying there are many solutions. out there you know who bypass captas but they often come with their own set of complications and it basically includes um you know like delays and increased complexity which is something I don't really like and if that's not enough on top of that you know there are also legal and ethical considerations to navigate um so you know scraping data without proper authorization can land in some pretty you know in a hot water potentially violating terms of service agreements and like copyright laws and all sorts of things plus scraping large amounts of data can also strain a website's um servers and disrupts its performance so it can raise like some ethical concerns about the impact on the other people as well and uh yeah there's just you know quite a lot of uh challenges um when we talk about scraping data from the internet so let's talk a little bit more about what's the right way to do it I've been using bright data and I shared it in my previous videos as well people loved it by the way if you haven't already seen that check it out but in this video we're solving these specific challenges so let's see what it's all about so we're going to be taking a look at the web unlocker tool by by bright data if you check the website uh you can see that it provides capture solving IP rotations and re-entries. JavaScript rendering uh 99.9% success rate pay only for Success which is pretty cool and by the way if you use the link in the description to sign up you'll get some additional credits or uh something like that like $15 I believe but you can check out the links in the description below so it provides website unlocking so AI powered website unlocking access to public web pages effortlessly with the advanced web un Locker platform and all the blockers that I mentioned like capture solving and uh browser fingerprinting iation so on and so forth takes care of that there proxy management as as well so no more burning through IPS um and it takes care takes care of it for you um there's also a buil-in browser for JavaScript rendering because certain websites use JavaScript uh uh that require the launch of a browser in order to fully display certain elements on the data so web un Locker can help with that and uh you know it's so it's pretty awesome you can try it for free and you can use the link in the description to get some credits as well we're obviously going to be seeing a demo and uh. you know we're going to be making a request we're going to be seeing how that works and get our data and it's going to be work for working for like we're going to try for various websites and um yeah the whole idea is you know for you to not get blocked and um an instance for this can be if you're let's say trying to automate Instagram for example um it can block you pretty easily right if Instagram sees like okay there's a bot your your account would be blocked so in order to not get blocked and um all these other things we're going to be using bright data so all these challenges as you can see you know uh being solved by bright data and uh we're going to be taking a look at demo right now but you can check more about it uh on the website you can see some nice partners and people who use it already and um this video is going to be set as a foundation for you to you know collect data for for all your work but also the courses and stuff that I do we're going to be utilizing it quite a lot to get the data and uh do dat do our day-to-day you know data related data scraping related tasks so I'm I'm sure you are getting blocked with one of the reasons that I just mentioned highly recommend trying trying out uh bright data and let's see how we can get started right now all right I am going to log in and you can start a free trial I'm going to log in we make devs not a problem and that should be good now I'm going to go to my I'm going to go to proxies and here you can see the web un Locker so you can just click on get started now here what we have is that um we're going to put a name in it so I can put any name that I want um Kunal demo or I can just put demo now geolocation targeting so obviously I already mentioned the benefits you can bypass captas and blocks and all the restrictions only pay for successful requests uh scrap public data from any website automated IP rotation and simulation and fingerprints geolocation targeting we're going to select uh country over here so you can see on the screen and uh do note that the zones the the name cannot be changed later on you can select premius uh premium domains if you want you can select um a requests uh some Advanced C custom headers and cookies when enabled. you can send custom headers and cookies along with your requests okay interesting geolocation targeting based on um in this Zone the location is selected per request so I'm going to do it country wise you will also be able to Target location based on the resolutions you specify Here country wise is fine I'm going to click on ADD you are about to create a new Zone demo are you sure I am sure that should be good access parameters you ready to send your first web unlocker request you can copy paste this command in your terminal to send your first web unlocker request in guides and different Pro check out the code Integrations as well if you want to do that you can review our fuel documentation we here okay coding integration examples can also be found over here so if I'm going to do an API for let's say python there you go pretty simple and here you can find the documentation as well Okay cool so getting started or a basic API and you can have a destination site so if you want to scrap um whatever you want to scrape you can put it over here you can add in your proxy you can add in a country for let's say if I add United States I'm going to hide the advanced options then you just select your language and here you go you have your language the whole um code written for you and try Java as well there you go pretty cool okay so that was the setting up part okay now let me try to scrape the good reads and here you can see here's my host uh my username my password you can add in more passwords allow IPS you can block some IPS Target host can configure it as well we'll check out the premium domains later on because there are some websites uh which are harder to scrape for example these ones for that you can enable premium domains uh in synchronous request we already mentioned that you can add in custom headers and cookies but uh let me just copy this paste it and let me just copy this URL you can also obviously integrate it in your um you know in your um code sample as well and that should give me codes Jack Browns when I begin in it see here we go so there was one blocker over here which was if I go to this URL you can't see it right now but if I do it in uh Incognito you will if I go to goodreads.com go to best quotes it yeah gives me like a popup or something okay so in order for me to not get blocked I'm using the the web the biodata platform other than that I want to show you um here I have it's all good um can check out the statistics total you know based on your usage um there's a list of websites like academy.com by go to academy.com and we try to scrape this it's going to be a bit bit tricky let me try that okay um academy.com requires a premium permission please enable the premium permission and then do it I can try that premium domains save Zone. demo plan will be changed yep not a problem configuration saved let's try it again so now the hardware to scrap websites I talk about academy.com don't allow these usually have like captas and uh you know a lot of other things let try it now should work okay there there you go see cool cool this a bit dirty right now but you can obviously parse it and scrape it and uh you know parse it and make it pretty and get some specific data out of it but uh that's it yeah pretty cool so you're able to scale like uh your you're able to scrape challenging websites as well uh now that you want carousel.com so you can see there's this little capture that just the the verification that just happened and here's a I don't know if you can see it going to move my screen here there you can see a little symbol over there um but I'm going to try and going to try and scrape this now there you go that should work easily there we go cool so you have that HTML page that you've just scraped the entire thing but it doesn't have to be like um you don't have to it I know it looks a bit dirty right now but uh yeah should be should be okay when you par it all right uh I went on Reddit SL webscraping and it has a question the most difficult websites to scrape someone said Walmart which has some nice upwards so what I'm going to do is I'm going to try and scrape um I'm going to try and scrape Walmart as well and um you know if sometimes you may find websites that are blocked behind a signin account then that that also you can work with the bright data in order to do that um I've done a separate video on such things as well so make sure you check it out uh shop all groceries um going to run this and see how it goes okay so I'm going to run this and see how how this goes there you go here we have it nice see vegetarian food seafood frozen meat very cool very cool all right now I know what you're saying Kunal it looks a bit ugly but uh you can also you know par this data like I do simply can do let's say python I have Walmart food section over here you States basic API demo and this is what the code that I just copied looks like I'm going to add in uh beautiful soup over here just to pass this uh this data and here I've just added it in the this entire thing is same what bright data has given me I have just made this change and let's say I'm trying to display all the specific data for example in this case all the paragraphs in this request so I just go to a new terminal uh and just run this file and it will give me in a prettier way all the paragraphs there you go stick chicken all the paragraphs I have gotten over here okay so let me show you a nice real example um I am going to do another python project um this is fine I'm going to scrape this website for a list of companies here in India uh any country is okay and I will just copy this copy this code and here. I'm just going to paste my code not a problem all right I'm going to remove this um need the extra stuff and don't need this as well it's fine let's keep it simple now what we want to do is we just want to get all the data for the companies okay all the company names let's say for my machine learning model I I need all the company names um for instance could be anything here I'm also going to import uh beautiful soup don't need this here performing request is fine but I'm going to save this thing actually in it is response so I'm going to say response is equal to this okay now soup is equal to beautiful soup response and HTML passer okay now we can just pass it I can say for I in soup dot find all let's say you want the company so I can say just heading to okay and here I can just say print I do text Dot I can just strip the extra you know uh spaces that should be it terminal new terminal there you go give me the name of the companies nice awesome cool TCS H Vio HDFC Bank Tech Mahindra exess bank so this is just an example now it depends on the type of data you know when you talk about machine learning um you can scrape Amazon you can get the prices of uh various fruit items or whatever based on you can also get the ears and everything and uh as simple as that how easy was that cool nice um but yeah pretty simple stuff you someone commented that Walmart was the really difficult one but not with bright data it's very cool and uh last thing I want to tell you is that uh. I highly recommend checking out the documentation so just go to you know um go to the bright data document which should be if you just go to Bright data documentation web un Locker here you can find the documentation okay and a lot more other things so I highly recommend checking it out and uh I've done a video on this already but there are also pre-built Uh custom data sets for you based on various categories that you can check out and custom data sets that you can create and uh proxies residential proxies if you're looking to try those out so it's an allinone solution that I highly recommend you know for you to try out and um use for your data scraping needs but yeah most difficult websites pretty easy to scrape and we'll be utilizing it quite a lot in the in the future in our boot camp and courses as well but yeah if you're making a project you need data publicly available data for your for your projects for your you know coursework or for just you know anything um check out bar data and if you use the link in the description below you'll get get some nice free credits as well to test it out and uh that's basically about it if you have any further questions let me know in the comment section below and uh also um if you have any suggestions uh like you want me to create a specific video about a specific use case or a website you want me to scrape let me know in the comment section below and uh I'll see you in the next one and um yeah go scrip data uh for training your machine learning models I'll be doing it in my boot camps as well yeah see you in the next one have a great [Music] day'''



print(len(text))
# Preprocess the text using spaCy
doc = nlp(text)

# Extract sentences from the preprocessed text
sentences = [sentence.text for sentence in doc.sents]

# Combine the sentences into a single string
processed_text = " ".join(sentences)

# Parse the processed text
parser = PlaintextParser.from_string(processed_text, Tokenizer("english"))

# Initialize the summarizer
summarizer = LsaSummarizer()

# Summarize the text
summary = summarizer(parser.document, 2)  # Summarize to 2 sentences

# Convert the summary to a string
summary_text = " ".join([str(sentence) for sentence in summary])

print(len(summary_text))
print(summary_text)
